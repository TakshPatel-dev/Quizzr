{"0":{"id":1155,"question":"Which command allows you to create a new application from source code, Docker images, or templates within OpenShift?","description":null,"answers":{"answer_a":"oc new-app <source>","answer_b":"oc create-app <source>","answer_c":"oc deploy-app <source>","answer_d":"oc start-app <source>","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"true","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":"answer_a","explanation":null,"tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Medium"},"1":{"id":10095,"question":"A team needs to manage Terraform versions across multiple projects. Which approach would be most maintainable?","description":"Implementing version management for Terraform.","answers":{"answer_a":"Let each developer choose their preferred version","answer_b":"Implement version management with tfenv and required_version constraints","answer_c":"Always use the latest version available","answer_d":"Never upgrade Terraform","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Version management with tfenv and required_version constraints provides the most maintainable approach. Tfenv tools manage multiple Terraform versions on developer machines. Required_version constraints explicitly declare compatible versions in configuration. This approach ensures consistent Terraform versions across all environments, prevents unexpected behavior due to version differences, enables controlled and tested version upgrades, makes version requirements explicit in the code, and creates a reliable development environment where Terraform behaves consistently regardless of where it's executed.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Medium"},"2":{"id":10121,"question":"A containerized application is experiencing unexpected shutdowns in production. Upon investigation, you notice the container is being terminated with exit code 137. Which approach would most effectively resolve this issue?","description":"Troubleshooting container termination issues in production.","answers":{"answer_a":"Increase logging verbosity within the application","answer_b":"Configure appropriate memory limits and implement graceful shutdown handling","answer_c":"Restart the container more frequently","answer_d":"Disable all health checks on the container","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Exit code 137 indicates that the container was terminated by the OOM (Out Of Memory) killer, meaning it exceeded its memory limits. Configuring appropriate memory limits ensures containers have sufficient memory while preventing a single container from consuming all resources. Implementing graceful shutdown handling allows the application to properly clean up resources when receiving termination signals. This approach addresses the root cause (memory issues) while improving application resilience, rather than just treating symptoms or creating workarounds that don't solve the underlying problem.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Medium"},"3":{"id":962,"question":"Which of the following are true for a pod in Kubernetes?","description":null,"answers":{"answer_a":"A Pod represents processes running on your Cluster","answer_b":"Pods are the simplest units in the Kubernetes object model that you create or deploy","answer_c":"A pod is the same as a container","answer_d":"You can have only 1 container running in 1 pod","answer_e":null,"answer_f":null},"multiple_correct_answers":"true","correct_answers":{"answer_a_correct":"true","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":null,"tip":null,"tags":[{"name":"Kubernetes"}],"category":"DevOps","difficulty":"Medium"},"4":{"id":911,"question":"Kubernetes cluster data is stored in which of the following?","description":null,"answers":{"answer_a":"Kube-apiserver","answer_b":"Kubelet","answer_c":"Etcd","answer_d":"None of the above","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"false","answer_c_correct":"true","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":null,"tip":null,"tags":[{"name":"Kubernetes"}],"category":"DevOps","difficulty":"Medium"},"5":{"id":10114,"question":"A team needs to implement infrastructure monitoring for their Terraform-managed resources. Which approach would be most comprehensive?","description":"Implementing effective infrastructure monitoring with Terraform.","answers":{"answer_a":"Check the cloud provider console periodically","answer_b":"Implement automated monitoring with threshold-based alerts and dashboards","answer_c":"React to issues when users report them","answer_d":"Focus only on cost monitoring","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Automated monitoring with threshold-based alerts and dashboards provides the most comprehensive monitoring solution. Automated monitoring continually checks infrastructure health. Threshold-based alerts notify teams before issues impact users. Dashboards provide visibility into infrastructure status. This approach enables proactive detection of issues before they affect users, provides comprehensive visibility into infrastructure performance and health, automates appropriate responses to common issues, centralizes monitoring across all infrastructure components, and creates a complete monitoring system that ensures infrastructure reliability.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Medium"},"6":{"id":10160,"question":"A team needs to implement a Docker-based local development environment that closely mirrors production. Which approach would be most effective?","description":"Creating production-like development environments with Docker.","answers":{"answer_a":"Use completely different configurations for development and production","answer_b":"Implement Docker Compose with production-parity services and volume mounts","answer_c":"Have developers work directly in production","answer_d":"Use simplified containers for development","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Docker Compose with production-parity services and volume mounts provides the most effective development environment. Production-parity services ensure development dependencies match production (same databases, queues, etc.). Volume mounts enable live code reloading without rebuilds. Docker Compose manages the multi-container environment declaratively. This approach creates development environments that behave like production while maintaining development efficiency, catches environment-specific issues early, enables realistic local testing before deployment, and gives developers a consistent, production-like environment regardless of their local OS.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Medium"},"7":{"id":1408,"question":"Which role in Docker Swarm is responsible for scheduling tasks and managing the cluster state?","description":"Docker Swarm roles define specific responsibilities for managing and executing tasks across nodes.","answers":{"answer_a":"Worker node","answer_b":"Manager node","answer_c":"Control node","answer_d":"Master node","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The Manager node in Docker Swarm is responsible for managing the cluster, scheduling tasks, and maintaining cluster state.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Medium"},"8":{"id":1233,"question":"How do Liveness and Readiness Probes benefit applications in OpenShift?","description":"Liveness and Readiness Probes monitor application health, restarting pods if necessary to ensure availability.","answers":{"answer_a":"They allow the application to automatically scale down during low traffic","answer_b":"They manage application logging","answer_c":"They ensure the health and availability of pods by detecting issues and restarting pods if necessary","answer_d":"They encrypt application data in transit","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"false","answer_c_correct":"true","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Liveness and Readiness Probes help maintain application uptime by monitoring pod health and restarting when issues are detected.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Medium"},"9":{"id":910,"question":"What used to be called a minion in Kubernetes cluster?","description":null,"answers":{"answer_a":"A component of the master node.","answer_b":"A monitoring engine used widely in Kubernetes.","answer_c":"Docker container service.","answer_d":"A worker node.","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"true","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":null,"tip":null,"tags":[{"name":"Kubernetes"}],"category":"DevOps","difficulty":"Medium"},"quizMetaData":{"createdBy":"18656047691","difficulty":"medium","topic":"devops","totalQuestions":"10","createdAt":"25/05/2025\t14:36:10","description":"xcvxcvxcv","time":"30"},"marks":"1","answer":{"0":"answer_a"}}