{"0":{"id":1421,"question":"Which instruction in a Dockerfile can be used to specify a default executable that always runs in the container?","description":"The `ENTRYPOINT` instruction allows a container to run a default executable.","answers":{"answer_a":"CMD","answer_b":"ENTRYPOINT","answer_c":"RUN","answer_d":"FROM","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The `ENTRYPOINT` instruction specifies a default executable that will always run in the container.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Medium"},"1":{"id":10093,"question":"A team needs to manage multiple Terraform providers efficiently. Which approach would be most maintainable?","description":"Managing multi-provider configurations in Terraform.","answers":{"answer_a":"Configure providers at the resource level","answer_b":"Implement provider aliases with configuration modules","answer_c":"Create separate Terraform configurations for each provider","answer_d":"Use only a single provider at a time","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Provider aliases with configuration modules provide the most maintainable multi-provider approach. Provider aliases enable using multiple configurations of the same provider. Configuration modules centralize provider settings for reuse. This approach enables clear organization of multi-region or multi-account resources, centralizes provider configuration for consistency, makes provider relationships explicit in the code, supports complex scenarios like cross-region or cross-account resource relationships, and creates a maintainable provider management system that scales with infrastructure complexity.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Medium"},"2":{"id":1245,"question":"Which command allows you to get a list of all OpenShift projects that you have access to?","description":"The oc get projects command provides a list of all projects accessible by the current user.","answers":{"answer_a":"oc list projects","answer_b":"oc view projects","answer_c":"oc get projects","answer_d":"oc show projects","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"false","answer_c_correct":"true","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The oc get projects command shows all projects accessible to the logged-in user.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Medium"},"3":{"id":10078,"question":"A team manages a growing Terraform codebase with many environments and regions. Which approach would best implement a DRY (Don't Repeat Yourself) methodology?","description":"Implementing DRY principles in Terraform configurations.","answers":{"answer_a":"Copy and paste code between environments with minor modifications","answer_b":"Implement a multi-level module strategy with composition patterns","answer_c":"Use count for everything","answer_d":"Regenerate configuration from scratch for each environment","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"A multi-level module strategy with composition patterns provides the most effective DRY implementation. Resource-level modules abstract individual resource complexity. Component-level modules combine resources into functional units. Stack-level modules assemble components into complete environments. This approach eliminates repetition across environments and regions, encapsulates complexity at the appropriate levels, enables consistent patterns to be applied throughout infrastructure, and creates a maintainable architecture that leverages reuse while supporting environment-specific customization.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Medium"},"4":{"id":1154,"question":"To view the configuration details, events, and status of a specific pod, which OpenShift command would you use?","description":null,"answers":{"answer_a":"oc describe pod <pod-name>","answer_b":"oc logs <pod-name>","answer_c":"oc status pod <pod-name>","answer_d":"oc get pod <pod-name> --details","answer_e":"oc describe pod <pod-name> --details","answer_f":"oc get pod <pod-name>"},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"true","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":"answer_a","explanation":null,"tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Medium"},"5":{"id":1408,"question":"Which role in Docker Swarm is responsible for scheduling tasks and managing the cluster state?","description":"Docker Swarm roles define specific responsibilities for managing and executing tasks across nodes.","answers":{"answer_a":"Worker node","answer_b":"Manager node","answer_c":"Control node","answer_d":"Master node","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The Manager node in Docker Swarm is responsible for managing the cluster, scheduling tasks, and maintaining cluster state.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Medium"},"6":{"id":1428,"question":"What is the difference between a container and an image in Docker?","description":"Images and containers have distinct purposes in Docker.","answers":{"answer_a":"An image is a running instance, while a container is an inactive snapshot","answer_b":"An image is a template, and a container is a running instance of that template","answer_c":"A container is a template, and an image is a running instance of that container","answer_d":"There is no difference","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"A Docker image is a template used to create containers, which are the running instances of that template.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Medium"},"7":{"id":911,"question":"Kubernetes cluster data is stored in which of the following?","description":null,"answers":{"answer_a":"Kube-apiserver","answer_b":"Kubelet","answer_c":"Etcd","answer_d":"None of the above","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"false","answer_c_correct":"true","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":null,"tip":null,"tags":[{"name":"Kubernetes"}],"category":"DevOps","difficulty":"Medium"},"8":{"id":10090,"question":"A team needs to implement a production-ready terraform remote backend. Which approach would be most robust?","description":"Implementing production-grade remote backends in Terraform.","answers":{"answer_a":"Use the local backend with manual backups","answer_b":"Implement S3 with state locking, encryption, and versioning","answer_c":"Use the HTTP backend without authentication","answer_d":"Store state files in a Git repository","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"S3 with state locking, encryption, and versioning provides the most robust remote backend. S3 offers highly durable storage for state files. DynamoDB enables state locking to prevent concurrent operations. Encryption protects sensitive data in state files. Versioning preserves state history. This approach prevents state corruption from concurrent operations, secures sensitive information in state files, provides reliable and durable state storage, maintains state history for auditing and recovery, and creates a production-ready backend that follows infrastructure-as-code best practices.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Medium"},"9":{"id":926,"question":"What is a Headless Service?","description":null,"answers":{"answer_a":"Headless Service is similar to that of a ‘Normal’ services but does not have a Cluster IP.","answer_b":"Headless Service is similar to that of a ‘Normal’ services but has a Cluster IP.","answer_c":null,"answer_d":null,"answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"true","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":null,"tip":null,"tags":[{"name":"Kubernetes"}],"category":"DevOps","difficulty":"Medium"},"quizMetaData":{"createdBy":"18656047691","difficulty":"medium","topic":"devops","totalQuestions":"10","createdAt":"25/05/2025\t14:51:36","description":"nbvnvbnvbn","time":"30"},"marks":"0","answer":{}}