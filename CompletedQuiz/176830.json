{"0":{"id":10086,"question":"A team is experiencing inconsistent execution results with Terraform. Which approach would most effectively improve reliability?","description":"Improving execution reliability in Terraform.","answers":{"answer_a":"Run Terraform multiple times until it works","answer_b":"Implement dependency management with explicit depends_on and provider configurations","answer_c":"Increase all timeouts to maximum values","answer_d":"Add sleep operations between resource creations","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Dependency management with explicit depends_on and provider configurations provides the most effective reliability improvement. Explicit depends_on ensures resources are created/modified in the correct order. Provider configurations with proper timeouts and retry logic handle transient failures. This approach addresses the root causes of inconsistent execution, ensures proper resource creation sequencing, handles cloud provider API limitations appropriately, makes dependencies explicit rather than relying on implicit behavior, and creates a more deterministic and reliable execution process.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Medium"},"1":{"id":1139,"question":"In OpenShift, what is the purpose of a DeploymentConfig?","description":null,"answers":{"answer_a":"To manage database connections","answer_b":"To define and control the lifecycle of applications and pods","answer_c":"To schedule automatic backups","answer_d":"To configure network policies","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":"answer_a","explanation":null,"tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Medium"},"2":{"id":1225,"question":"What role does the OpenShift Registry play in application deployment?","description":"The OpenShift Registry stores container images used for application builds and deployments.","answers":{"answer_a":"It schedules pods to nodes","answer_b":"It stores container images for application builds and deployments","answer_c":"It defines network policies for services","answer_d":"It handles service discovery","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The OpenShift Registry serves as a container image repository for applications being built and deployed in the cluster.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Medium"},"3":{"id":10134,"question":"A team needs to troubleshoot a containerized application that appears to be consuming excessive CPU. Which approach would be most effective?","description":"Diagnosing CPU issues in containerized applications.","answers":{"answer_a":"Restart the container repeatedly","answer_b":"Implement container-aware profiling and resource monitoring","answer_c":"Add more memory to the container","answer_d":"Switch to a different base image","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Container-aware profiling and resource monitoring provides the most effective CPU troubleshooting approach. Tools like cAdvisor, Docker stats, or Prometheus with container metrics enable real-time visibility into CPU usage patterns. Profiling tools that can attach to processes inside containers (like perf or pprof) identify specific functions or code paths causing high CPU usage. This approach precisely identifies not just that CPU usage is high but exactly why it's high, enabling targeted optimization instead of general resource adjustments or restart-based workarounds that don't address the root cause.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Medium"},"4":{"id":1015,"question":"What Are Kubernetes Controllers?","description":null,"answers":{"answer_a":"Kubernetes controllers are Replicaset, Deployment controller.","answer_b":"Kubernetes controllers are Surverless, Deployment capacitor.","answer_c":null,"answer_d":null,"answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"true","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":null,"tip":null,"tags":[{"name":"Kubernetes"}],"category":"DevOps","difficulty":"Medium"},"5":{"id":10068,"question":"A team needs to implement resource naming that is consistent across their organization. Which approach would be most maintainable?","description":"Implementing consistent resource naming in Terraform.","answers":{"answer_a":"Let each team choose their own naming convention","answer_b":"Implement a label module with enforced organizational patterns","answer_c":"Hardcode names in each resource","answer_d":"Use random names for all resources","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"A label module with enforced organizational patterns provides the most maintainable naming solution. A central label module generates resource names following organizational standards. Required inputs ensure necessary context (environment, purpose, etc.) is included. This approach ensures consistent naming across the organization, makes name components and purpose explicit, simplifies finding and managing resources, enables enforcement of naming policies, and creates a scalable system where naming conventions can be updated organization-wide through the module.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Medium"},"6":{"id":1420,"question":"What is the purpose of the `EXPOSE` instruction in a Dockerfile?","description":"The `EXPOSE` instruction indicates which port the container will use for external connections.","answers":{"answer_a":"It starts a port listener","answer_b":"It makes the port accessible on the internet","answer_c":"It informs Docker that the container will listen on a specific port","answer_d":"It opens the container to all network traffic","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"false","answer_c_correct":"true","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The `EXPOSE` instruction specifies the port on which the container listens for connections.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Medium"},"7":{"id":10100,"question":"A team needs to implement a solution for tracking infrastructure costs with Terraform. Which approach would be most effective?","description":"Implementing cost tracking for Terraform-managed infrastructure.","answers":{"answer_a":"Manually review cloud provider bills","answer_b":"Implement systematic tagging with cost allocation and estimation tools","answer_c":"Set a fixed infrastructure budget","answer_d":"Create separate accounts for each project","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Systematic tagging with cost allocation and estimation tools provides the most effective cost tracking approach. Comprehensive tagging identifies resource ownership and purpose. Cost allocation tools group costs by tags. Estimation tools (like Infracost) predict costs before deployment. This approach enables accurate attribution of costs to teams and projects, provides visibility into cost implications before changes are deployed, helps identify cost optimization opportunities, enables budgeting and forecasting, and creates a comprehensive cost management system integrated with the infrastructure deployment process.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Medium"},"8":{"id":10142,"question":"A team needs to implement Docker in a CI/CD pipeline. Which approach would provide the fastest and most reliable builds?","description":"Optimizing Docker in CI/CD pipelines.","answers":{"answer_a":"Build images from scratch in each CI job","answer_b":"Implement distributed caching with optimized Dockerfiles and parallelization","answer_c":"Use the same image for all applications","answer_d":"Build images only on developer machines","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Distributed caching with optimized Dockerfiles and parallelization provides the fastest and most reliable CI/CD implementation. Distributed caching through registry mirrors or built-in CI caching mechanisms preserves and shares layers across builds. Optimized Dockerfiles maximize cache usage through proper instruction ordering. Parallelization building multiple images simultaneously reduces total build time. This approach significantly speeds up builds while maintaining consistency and reliability, creates efficient pipelines that scale with project complexity, and enables fast feedback for developers without sacrificing build quality.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Medium"},"9":{"id":1014,"question":"______ is distributed key-value store that provides a reliable way to store data that needs to be accessed by a distributed system or cluster of machines.","description":null,"answers":{"answer_a":"A Kubernetes pod","answer_b":"A Kubernetes service","answer_c":"A Kubernetes volume","answer_d":"etcd","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"true","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":null,"tip":null,"tags":[{"name":"Kubernetes"}],"category":"DevOps","difficulty":"Medium"},"quizMetaData":{"createdBy":"18656047691","difficulty":"medium","topic":"devops","totalQuestions":"10","createdAt":"25/05/2025\t02:15:51","description":"fdssdfsfd","time":"30"},"marks":"0","answer":{"0":"answer_a"}}