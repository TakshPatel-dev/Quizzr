{"0":{"id":10160,"question":"A team needs to implement a Docker-based local development environment that closely mirrors production. Which approach would be most effective?","description":"Creating production-like development environments with Docker.","answers":{"answer_a":"Use completely different configurations for development and production","answer_b":"Implement Docker Compose with production-parity services and volume mounts","answer_c":"Have developers work directly in production","answer_d":"Use simplified containers for development","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Docker Compose with production-parity services and volume mounts provides the most effective development environment. Production-parity services ensure development dependencies match production (same databases, queues, etc.). Volume mounts enable live code reloading without rebuilds. Docker Compose manages the multi-container environment declaratively. This approach creates development environments that behave like production while maintaining development efficiency, catches environment-specific issues early, enables realistic local testing before deployment, and gives developers a consistent, production-like environment regardless of their local OS.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Medium"},"1":{"id":10065,"question":"A team is setting up a new Terraform project and needs to manage backend configuration. Which approach would be most maintainable for a growing team?","description":"Implementing scalable backend configuration in Terraform.","answers":{"answer_a":"Use local state and commit it to version control","answer_b":"Implement a partial configuration pattern with backend.hcl files","answer_c":"Hardcode backend configuration in every repository","answer_d":"Switch backends frequently to distribute load","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"A partial configuration pattern with backend.hcl files provides the most maintainable backend setup. Partial configuration separates constant backend details (bucket name, region) from varying details (key path). Backend.hcl files store environment-specific settings outside version control. This approach avoids hardcoding environment-specific values in shared code, simplifies working with multiple environments, enables consistent backend usage across projects, makes onboarding new team members easier, and creates a flexible system that scales as the team and infrastructure grow.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Medium"},"2":{"id":10172,"question":"A team using Docker Compose is experiencing issues with container startup order, causing application failures. Which approach would most effectively resolve these issues?","description":"Managing container dependencies and startup order.","answers":{"answer_a":"Start all containers manually in the correct order","answer_b":"Implement dependency resolution with health checks and connection retries","answer_c":"Put all services in a single container","answer_d":"Add sleep commands to delay service startup","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Dependency resolution with health checks and connection retries provides the most robust startup orchestration. Dependency resolution through depends_on establishes the basic startup sequence. Health checks ensure dependent services are actually ready, not just running. Connection retries in application code handle temporary unavailability gracefully. This approach ensures services start in the correct order while verifying actual service readiness, handles the reality that services take variable time to initialize, creates resilient applications that can handle temporary dependency unavailability, and establishes a robust multi-container startup process without arbitrary timing hacks.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Medium"},"3":{"id":1241,"question":"In OpenShift, which component is responsible for managing routing of HTTP and HTTPS traffic to services?","description":"Routes in OpenShift manage the routing of HTTP and HTTPS traffic to services.","answers":{"answer_a":"Route","answer_b":"Service","answer_c":"Cluster IP","answer_d":"Load Balancer","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"true","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Routes are used in OpenShift to expose services externally, handling HTTP and HTTPS traffic.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Medium"},"4":{"id":10168,"question":"A team needs to implement proper logging for containerized applications running across multiple hosts. Which approach would be most effective?","description":"Implementing comprehensive logging for containerized environments.","answers":{"answer_a":"Allow each application to implement its own logging solution","answer_b":"Implement centralized logging with container context and structured formats","answer_c":"Store logs only within each container","answer_d":"Disable logging to improve performance","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Centralized logging with container context and structured formats provides the most effective logging solution. Centralized logging aggregates logs from all containers into a unified system. Container context (adding metadata about container ID, image, and host) enables filtering and correlation. Structured formats (JSON or similar) make logs machine-parseable. This approach preserves logs beyond container lifecycle, enables correlation across distributed services, supports sophisticated querying and analysis, maintains consistency across all applications, and creates comprehensive logging that scales across multi-host containerized environments.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Medium"},"5":{"id":10073,"question":"A team needs to manage Terraform state for multiple isolated environments. Which approach would be most secure and maintainable?","description":"Implementing secure state management in Terraform.","answers":{"answer_a":"Use a single state file for all environments","answer_b":"Implement workspace isolation with access controls and state encryption","answer_c":"Keep state files on local developer machines","answer_d":"Email state files between team members","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Workspace isolation with access controls and state encryption provides the most secure and maintainable state management. Workspaces keep environment states completely separate. Access controls restrict who can access each environment's state. Encryption protects sensitive data within state files. This approach maintains strict isolation between environments (particularly important for production), implements least-privilege access to state files, protects sensitive information in state from unauthorized access, and creates a secure state management system that scales across multiple environments.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Medium"},"6":{"id":10093,"question":"A team needs to manage multiple Terraform providers efficiently. Which approach would be most maintainable?","description":"Managing multi-provider configurations in Terraform.","answers":{"answer_a":"Configure providers at the resource level","answer_b":"Implement provider aliases with configuration modules","answer_c":"Create separate Terraform configurations for each provider","answer_d":"Use only a single provider at a time","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Provider aliases with configuration modules provide the most maintainable multi-provider approach. Provider aliases enable using multiple configurations of the same provider. Configuration modules centralize provider settings for reuse. This approach enables clear organization of multi-region or multi-account resources, centralizes provider configuration for consistency, makes provider relationships explicit in the code, supports complex scenarios like cross-region or cross-account resource relationships, and creates a maintainable provider management system that scales with infrastructure complexity.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Medium"},"7":{"id":952,"question":"What are the functions of Replication controller?","description":null,"answers":{"answer_a":"It is responsible to control and administer the lifecycle of the pod.","answer_b":"It helps the user to check the running status of the pod","answer_c":"It is responsible to monitor and verify whether the allowed number of pod replicas were running","answer_d":"It is responsible for routing the ingress traffic","answer_e":null,"answer_f":null},"multiple_correct_answers":"true","correct_answers":{"answer_a_correct":"true","answer_b_correct":"true","answer_c_correct":"true","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":null,"tip":null,"tags":[{"name":"Kubernetes"}],"category":"DevOps","difficulty":"Medium"},"8":{"id":1240,"question":"Which command would you use to delete a specific project in OpenShift?","description":"The oc delete project command deletes a specified project in OpenShift.","answers":{"answer_a":"oc project delete <project-name>","answer_b":"oc delete namespace <namespace-name>","answer_c":"oc delete project <project-name>","answer_d":"oc remove project <project-name>","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"false","answer_c_correct":"true","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Using oc delete project <project-name> deletes the entire specified project from OpenShift.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Medium"},"9":{"id":1430,"question":"What is a best practice for keeping Docker images as small as possible?","description":"Small Docker images load faster and consume fewer resources.","answers":{"answer_a":"Use large base images","answer_b":"Use multi-stage builds and remove unnecessary files","answer_c":"Install all software in a single RUN instruction","answer_d":"Avoid using Dockerfiles","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Using multi-stage builds and removing unnecessary files helps minimize the size of Docker images.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Medium"},"quizMetaData":{"createdBy":"18656047691","difficulty":"medium","topic":"devops","totalQuestions":"10","createdAt":"25/05/2025\t14:34:41","description":"xcv","time":"30"},"marks":"0","answer":{"0":"answer_a"}}