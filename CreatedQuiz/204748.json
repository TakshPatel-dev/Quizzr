{"0":{"id":10123,"question":"A Docker-based microservice architecture is experiencing network-related performance issues in production. Which approach would be most effective for diagnosing the root cause?","description":"Troubleshooting network performance in containerized environments.","answers":{"answer_a":"Rebuild all container images with the latest base images","answer_b":"Implement comprehensive network monitoring with container-aware tools","answer_c":"Switch to host networking mode for all containers","answer_d":"Increase CPU allocation for all containers","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Container-aware network monitoring tools provide visibility into container-specific network metrics, inter-container communication patterns, and potential bottlenecks in the Docker network stack. Tools like Prometheus with cAdvisor, Cilium, or Docker's built-in stats can track network throughput, latency, connection states, and packet drops at the container level. This comprehensive approach enables identifying specific network issues within the microservice architecture, whether they're related to specific services, overall network configuration, DNS resolution delays, or network driver problems.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Hard"},"1":{"id":1379,"question":"Which Keycloak token is used by OpenShift to validate a user's identity during login?","description":"Keycloak issues several token types, but one is essential for OpenShift authentication.","answers":{"answer_a":"Access Token","answer_b":"Refresh Token","answer_c":"ID Token","answer_d":"Bearer Token","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"true","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"OpenShift uses the Access Token provided by Keycloak to authenticate a user's identity during login.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"2":{"id":1318,"question":"In OpenShift, what is the main advantage of using a DaemonSet for deploying specific pods?","description":"DaemonSets ensure that specific pods are present on each node, useful for monitoring and logging.","answers":{"answer_a":"Ensures high availability","answer_b":"Guarantees a pod is deployed on every node","answer_c":"Increases the number of replicas automatically","answer_d":"Enhances network performance","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"DaemonSets deploy pods on all or specific nodes, which is useful for distributed tasks like monitoring.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"3":{"id":10111,"question":"A team needs to implement a method for handling long-running operations in Terraform. Which approach would be most robust?","description":"Handling asynchronous operations in Terraform.","answers":{"answer_a":"Increase all timeouts to maximum values","answer_b":"Implement asynchronous handling with creation-time provisioners and completion detection","answer_c":"Avoid resources with long-running operations","answer_d":"Run terraform apply multiple times","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Asynchronous handling with creation-time provisioners and completion detection provides the most robust long-running operation solution. Creation-time provisioners trigger asynchronous workflows. Completion detection (through polling or event hooks) determines when operations finish. This approach handles operations that exceed Terraform's default timeouts, enables managing truly asynchronous processes, prevents Terraform from timing out during extended operations, properly manages dependencies between async operations, and creates a reliable system for handling complex infrastructure that includes long-running provisioning tasks.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Hard"},"4":{"id":1250,"question":"Which command would you use to force a restart of all pods in a DeploymentConfig?","description":"The oc rollout latest command triggers a new rollout, effectively restarting all pods in the specified DeploymentConfig.","answers":{"answer_a":"oc restart dc <DeploymentConfig-name>","answer_b":"oc redeploy <DeploymentConfig-name>","answer_c":"oc rollout latest <DeploymentConfig-name>","answer_d":"oc refresh dc <DeploymentConfig-name>","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"false","answer_c_correct":"true","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The oc rollout latest command forces a new deployment rollout, restarting all pods in the DeploymentConfig.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"5":{"id":10116,"question":"A team needs to implement a solution for managing API credentials in Terraform securely. Which approach would be most secure?","description":"Implementing secure credential management in Terraform.","answers":{"answer_a":"Store credentials in environment variables","answer_b":"Implement a secrets management service with dynamic credentials","answer_c":"Store credentials in terraform.tfvars and gitignore it","answer_d":"Hardcode masked credentials in the Terraform code","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"A secrets management service with dynamic credentials provides the most secure credential approach. Secrets management services (like HashiCorp Vault or AWS Secrets Manager) store credentials securely. Dynamic credentials are generated just-in-time with limited lifespans. This approach eliminates long-lived static credentials, prevents credential exposure in version control or state files, implements proper secrets management practices, provides audit trails for credential access, creates time-limited credentials following least-privilege principles, and establishes a secure credential management system that integrates with the infrastructure provisioning process.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Hard"},"6":{"id":1308,"question":"How can you configure a DeploymentConfig to perform a custom action after the deployment succeeds?","description":"Lifecycle hooks in DeploymentConfigs allow for custom actions during deployments.","answers":{"answer_a":"Add a post-deployment hook","answer_b":"Set an oc deploy trigger","answer_c":"Define a post-lifecycle handler","answer_d":"Create an after-success trigger","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"true","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"A post-deployment hook allows a custom action to run after a DeploymentConfig succeeds.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"7":{"id":1313,"question":"How does OpenShift determine which policy to apply if multiple NetworkPolicies are set on a single namespace?","description":"Understanding the behavior of NetworkPolicies in a multi-policy environment is crucial for managing network security.","answers":{"answer_a":"It applies the most restrictive policy","answer_b":"It applies the first policy in alphabetical order","answer_c":"It applies all NetworkPolicies to the namespace","answer_d":"It applies the least restrictive policy","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"false","answer_c_correct":"true","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"All NetworkPolicies in a namespace are combined and applied to the pods within that namespace.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"8":{"id":1266,"question":"Which oc command lists all the images used by deployments in a project?","description":"Using oc get pods --all-namespaces -o wide can display the images of deployments.","answers":{"answer_a":"oc get all --images","answer_b":"oc list images --deployments","answer_c":"oc get pods -o wide","answer_d":"oc get deployments --images","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"false","answer_c_correct":"true","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The oc get pods -o wide command displays the images associated with deployments in a wide format.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"9":{"id":1298,"question":"What purpose does the etcd ‘alarm’ feature serve in OpenShift?","description":"The etcd alarm feature helps notify administrators of storage issues or failures.","answers":{"answer_a":"It alerts when a node goes offline","answer_b":"It triggers when the etcd storage reaches its limit","answer_c":"It sends notifications for high CPU usage","answer_d":"It alerts when etcd exceeds memory thresholds","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The etcd alarm feature issues alerts when the backend storage limit is reached, preventing new writes.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"10":{"id":1335,"question":"How does OpenShift handle pod termination during an autoscale down event?","description":"During autoscale down events, OpenShift determines which pods to terminate based on specific criteria.","answers":{"answer_a":"Pods are terminated in alphabetical order","answer_b":"OpenShift terminates the pod with the lowest resource usage","answer_c":"OpenShift uses a last-in, first-out (LIFO) termination approach","answer_d":"OpenShift terminates pods based on a random selection","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"false","answer_c_correct":"true","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"OpenShift typically uses a LIFO (last-in, first-out) approach when terminating pods during a scale-down event.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"11":{"id":10150,"question":"A team is deploying Docker in an environment with strict compliance requirements. Which approach would best satisfy auditing needs?","description":"Implementing Docker for compliance-focused environments.","answers":{"answer_a":"Provide compliance teams access to production systems","answer_b":"Implement comprehensive logging with RBAC and image provenance tracking","answer_c":"Avoid using Docker in compliance-focused environments","answer_d":"Generate manual reports about container usage","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Comprehensive logging with RBAC and image provenance tracking satisfies stringent compliance requirements. Comprehensive logging captures all actions affecting containers and images with details on who performed them. Role-Based Access Control (RBAC) restricts system access based on user roles. Image provenance tracking maintains verifiable records of image origins and modifications. This approach provides complete audit trails for compliance verification, enforces separation of duties through access controls, enables demonstrating compliance with specific regulations, and creates a secure and auditable container environment suitable for regulated industries.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Hard"},"12":{"id":10133,"question":"Your organization needs to implement container orchestration for a production environment. Which key factors should primarily drive the decision between Docker Swarm and Kubernetes?","description":"Selecting appropriate container orchestration solutions.","answers":{"answer_a":"Choose based only on community size","answer_b":"Evaluate operational complexity, scaling requirements, and integration needs","answer_c":"Select the newest technology available","answer_d":"Choose based only on cost considerations","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Operational complexity, scaling requirements, and integration needs are the most important factors for orchestration decisions. Operational complexity reflects the team's expertise and available resources - Swarm offers simplicity while Kubernetes provides more features with higher complexity. Scaling requirements determine whether Swarm's straightforward scaling meets needs or if Kubernetes' advanced scheduling and auto-scaling capabilities are necessary. Integration needs consider existing infrastructure, tools, and cloud services that must work with the orchestration solution. This balanced approach ensures the selected technology aligns with both current capabilities and future requirements.","tip":null,"tags":[{"name":"Docker"}],"category":"DevOps","difficulty":"Hard"},"13":{"id":1299,"question":"How can you manually clear an alarm in etcd after resolving a storage issue?","description":"Clearing an etcd alarm manually is necessary once a storage issue is resolved, allowing etcd to resume normal operations.","answers":{"answer_a":"etcdctl alarm reset","answer_b":"etcdctl alarm clear","answer_c":"etcdctl alarm disarm","answer_d":"etcdctl reset alarms","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"true","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The etcdctl alarm reset command clears any triggered alarms, allowing etcd to continue normal operations.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"14":{"id":10098,"question":"A team needs to implement Terraform for a regulated industry with strict compliance requirements. Which approach would be most compliant?","description":"Implementing Terraform for compliance-focused environments.","answers":{"answer_a":"Use Terraform only for development environments","answer_b":"Implement workflow controls with policy enforcement and audit trails","answer_c":"Get manual approval for each resource","answer_d":"Avoid automation to ensure human oversight","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"true","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"Workflow controls with policy enforcement and audit trails provide the most compliant Terraform implementation. Workflow controls enforce separation of duties and approval processes. Policy enforcement ensures infrastructure meets compliance requirements. Comprehensive audit trails document all changes and approvals. This approach automates compliance verification rather than relying solely on manual processes, maintains complete records for audit purposes, enforces regulatory requirements consistently, prevents non-compliant infrastructure from being deployed, and creates a demonstrably compliant infrastructure process suitable for regulated industries.","tip":null,"tags":[{"name":"Terraform"}],"category":"DevOps","difficulty":"Hard"},"15":{"id":1389,"question":"What purpose does the `offline_access` scope in Keycloak serve for OpenShift?","description":"Offline access tokens allow users to maintain access without active sessions.","answers":{"answer_a":"It allows users to access OpenShift without a current session","answer_b":"It refreshes tokens without user interaction","answer_c":"It grants admin-level access to resources","answer_d":"It disables token expiration","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"true","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The `offline_access` scope in Keycloak allows users to maintain access to OpenShift even when they are not actively logged in.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"16":{"id":1360,"question":"Which flag is commonly used to specify the configuration file for the `openshift-kube-apiserver` on startup?","description":"The configuration file contains essential settings for the API server’s operation.","answers":{"answer_a":"--config","answer_b":"--config-file","answer_c":"--configuration","answer_d":"--settings","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"true","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The `--config` flag is used to specify the configuration file path for the `openshift-kube-apiserver` on startup.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"17":{"id":1357,"question":"Which port does the `openshift-kube-apiserver` typically listen on for secure API traffic?","description":"The API server in OpenShift typically listens on a specific port for secure communication.","answers":{"answer_a":"6443","answer_b":"443","answer_c":"8080","answer_d":"2379","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"true","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The `openshift-kube-apiserver` listens on port 6443 for secure API traffic by default.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"18":{"id":1322,"question":"Which command allows you to create a ConfigMap from a file in OpenShift?","description":"Creating ConfigMaps from files is a common method for managing configurations in OpenShift.","answers":{"answer_a":"oc create configmap <name> --from-file=<file-path>","answer_b":"oc apply configmap <name> --file=<file-path>","answer_c":"oc import configmap <name> --file=<file-path>","answer_d":"oc load configmap <name> <file-path>","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"true","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"false","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"The oc create configmap command with --from-file=<file-path> option creates a ConfigMap from a specified file.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"19":{"id":1362,"question":"What authentication mechanism does `openshift-kube-apiserver` use to authenticate requests from other Kubernetes components?","description":"Inter-component authentication ensures that only trusted components can interact with the API server.","answers":{"answer_a":"Service Account tokens","answer_b":"LDAP","answer_c":"Basic Auth","answer_d":"Mutual TLS","answer_e":null,"answer_f":null},"multiple_correct_answers":"false","correct_answers":{"answer_a_correct":"false","answer_b_correct":"false","answer_c_correct":"false","answer_d_correct":"true","answer_e_correct":"false","answer_f_correct":"false"},"correct_answer":null,"explanation":"`openshift-kube-apiserver` uses mutual TLS for authenticating requests between Kubernetes components, ensuring secure communication.","tip":null,"tags":[{"name":"Openshift"}],"category":"DevOps","difficulty":"Hard"},"quizMetaData":{"createdBy":"18656047691","difficulty":"hard","topic":"devops","totalQuestions":"20","createdAt":"29/05/2025\t23:44:38","description":"fdgfdfdgfd","time":"30"}}